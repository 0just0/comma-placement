{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import seqeval\n",
    "\n",
    "import spacy\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dtemnov/Projects/comma-placement/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"just097/wiki-comma-placement\"\n",
    "wiki_comma_placement = load_dataset(dataset_path)\n",
    "LABEL_LIST = [\"O\", \"B-COMMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_comma_placement[\"test\"][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kovacs only had two campus visits: Division II, Hillsdale and Toledo ( a school 13 miles from his high school ).\n"
     ]
    }
   ],
   "source": [
    "try_sample = wiki_comma_placement[\"test\"][21]\n",
    "\n",
    "text = \" \".join(try_sample[\"tokens\"]).strip()\n",
    "clean_text = model.preprocess(text)\n",
    "punct_text = model.restore_punctuation(text)\n",
    "print(punct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = wiki_comma_placement[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_sample(sentence: str) -> str:\n",
    "    sentence = sentence.strip()\n",
    "    words = [word.text for word in nlp(sentence)]\n",
    "    tags = []\n",
    "    clean_words = []\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == \",\":\n",
    "            continue\n",
    "        if words[i + 1] == \",\":\n",
    "            clean_words.append(words[i])\n",
    "            tags.append(1)\n",
    "        else:\n",
    "            clean_words.append(words[i])\n",
    "            tags.append(0)\n",
    "    clean_words.append(words[-1])\n",
    "    tags.append(0)\n",
    "    assert len(tags) == len(clean_words)\n",
    "    return {\"tokens\": clean_words, \"tags\": tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_text(example):\n",
    "    text = \" \".join(example[\"tokens\"]).strip()\n",
    "    clean_text = model.preprocess(text)\n",
    "    clean_text = \" \".join(clean_text).strip()\n",
    "    punct_text = model.restore_punctuation(clean_text)\n",
    "    return sentence_to_sample(punct_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate restored sentences with baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_texts = test_subset.map(restore_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_to_tags(labled_words):\n",
    "    pred_tags = [1 if token[1] == ',' else 0 for token in labled_words]\n",
    "    pred_tags.append(0)\n",
    "    return pred_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = predicted_to_tags(labled_words)\n",
    "\n",
    "print(try_sample[\"tags\"])\n",
    "print(predicted_tags)\n",
    "\n",
    "assert len(try_sample[\"tags\"]) == len(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predicted_tags, gt_tags):\n",
    "    true_predictions = [[LABEL_LIST[p] for p in predicted_tags]]\n",
    "    true_labels = [[LABEL_LIST[t] for t in gt_tags]]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples:\n[19]\n[18]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m compute_metrics(predicted_tags, try_sample[\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "\u001b[1;32m/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m true_predictions \u001b[39m=\u001b[39m [[LABEL_LIST[p] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m predicted_tags]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [[LABEL_LIST[t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m gt_tags]]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m seqeval\u001b[39m.\u001b[39;49mcompute(predictions\u001b[39m=\u001b[39;49mtrue_predictions, references\u001b[39m=\u001b[39;49mtrue_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m: results[\u001b[39m\"\u001b[39m\u001b[39moverall_precision\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m: results[\u001b[39m\"\u001b[39m\u001b[39moverall_recall\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m: results[\u001b[39m\"\u001b[39m\u001b[39moverall_f1\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: results[\u001b[39m\"\u001b[39m\u001b[39moverall_accuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dtemnov/Projects/comma-placement/notebooks/eval_baseline.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m }\n",
      "File \u001b[0;32m~/Projects/comma-placement/.venv/lib/python3.11/site-packages/evaluate/module.py:462\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m inputs \u001b[39m=\u001b[39m {input_name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[input_name] \u001b[39mfor\u001b[39;00m input_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_names()}\n\u001b[1;32m    461\u001b[0m \u001b[39mwith\u001b[39;00m temp_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed):\n\u001b[0;32m--> 462\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcompute_kwargs)\n\u001b[1;32m    464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_writer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_writer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c/seqeval.py:136\u001b[0m, in \u001b[0;36mSeqeval._compute\u001b[0;34m(self, predictions, references, suffix, scheme, mode, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mScheme should be one of [IOB1, IOB2, IOE1, IOE2, IOBES, BILOU], got \u001b[39m\u001b[39m{\u001b[39;00mscheme\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m report \u001b[39m=\u001b[39m classification_report(\n\u001b[1;32m    137\u001b[0m     y_true\u001b[39m=\u001b[39;49mreferences,\n\u001b[1;32m    138\u001b[0m     y_pred\u001b[39m=\u001b[39;49mpredictions,\n\u001b[1;32m    139\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m    140\u001b[0m     output_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    141\u001b[0m     scheme\u001b[39m=\u001b[39;49mscheme,\n\u001b[1;32m    142\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    143\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    144\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m report\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmacro avg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m report\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mweighted avg\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/comma-placement/.venv/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:692\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, digits, suffix, output_dict, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    689\u001b[0m     reporter \u001b[39m=\u001b[39m StringReporter(width\u001b[39m=\u001b[39mwidth, digits\u001b[39m=\u001b[39mdigits)\n\u001b[1;32m    691\u001b[0m \u001b[39m# compute per-class scores.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m p, r, f1, s \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m    693\u001b[0m     y_true, y_pred,\n\u001b[1;32m    694\u001b[0m     average\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    695\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    696\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    697\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(target_names, p, r, f1, s):\n\u001b[1;32m    700\u001b[0m     reporter\u001b[39m.\u001b[39mwrite(\u001b[39m*\u001b[39mrow)\n",
      "File \u001b[0;32m~/Projects/comma-placement/.venv/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(true_sum, \u001b[39mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[39m=\u001b[39m _precision_recall_fscore_support(\n\u001b[1;32m    131\u001b[0m     y_true, y_pred,\n\u001b[1;32m    132\u001b[0m     average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    133\u001b[0m     warn_for\u001b[39m=\u001b[39;49mwarn_for,\n\u001b[1;32m    134\u001b[0m     beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m    135\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    136\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    137\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    138\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m    139\u001b[0m     extract_tp_actual_correct\u001b[39m=\u001b[39;49mextract_tp_actual_correct\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
      "File \u001b[0;32m~/Projects/comma-placement/.venv/lib/python3.11/site-packages/seqeval/metrics/v1.py:122\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options:\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(average_options))\n\u001b[0;32m--> 122\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    124\u001b[0m pred_sum, tp_sum, true_sum \u001b[39m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/comma-placement/.venv/lib/python3.11/site-packages/seqeval/metrics/v1.py:101\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_true) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(y_pred) \u001b[39mor\u001b[39;00m len_true \u001b[39m!=\u001b[39m len_pred:\n\u001b[1;32m    100\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(len_true, len_pred)\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples:\n[19]\n[18]"
     ]
    }
   ],
   "source": [
    "compute_metrics(predicted_tags, try_sample[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
